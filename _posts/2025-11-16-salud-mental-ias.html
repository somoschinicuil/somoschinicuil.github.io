---
layout: post
trait: 'post'
title: "Salud mental y la inteligencia artificial Ft. Majo Castañeda"
date: 2025-11-16 00:00:00 +0200
tags: [minicuil, tecnologia, videos, fediverso]
description: "Qué pasa con las mal nombradas Inteligencias emocionales y la gente que las usa para buscar ayuda psicológica"
thumbVideo: base
urlAnartist: 5c31d70b-89b2-47a4-87f3-f125561bbff5
---

<p>Según un estudio del "Harvard Business Review" el principal uso a nivel personal para chatbots como chatgpt es para buscar compañía y un sustituto de terapia. [1]</p>
<p>A parte de acercarnos a vivir en episodio de "Black Mirror", ¿que nos dice este dato sobre la forma que estamos socializando y organizando nuestra sociedad?</p>
<p>En los últimos meses se han reportado muchos casos de pacientes psiquiátricos que han dejado de medicarse [2], 
    gente teniendo crisis emocionales [3] (y hasta espirituales [4]), y el origen de estos casos: personas hablando con las malnombradas inteligencias artificiales. 
    E inclusive, se ha demostrado que el abuso de las IA pueden generar una tendencia de dependencia a la tecnología: ocasionando pérdida de habilidades como la memoria, 
    el razonamiento crítico, adaptabilidad y resolución de problemas complejos [5]. </p>
<p>Para empezar, esta tecnología no estuvo diseñada para ofrecer ayuda psicológica, y mucho menos a hacerse cargo del libre albedrío humano. 
    Y a pesar de que las primeras versiones tenían controles de seguridad que le recordaban al usuario que no estaban equipadas para dar apoyo emocional o consejo psicológico [5], 
    las nuevas versiones de estos chatbots están diseñadas para simular conversaciones más humanas y reafirmar todo lo que los usuarios les ecriben [6].
     Es más, ya hay apps con un chatbot psicológico para acompañar al usuario en momentos de crisis emocionales (App Liven). </p>
<p>Y el centro de este problema no es un tema tecnológico, este problema tiene al menos 3 implicaciones sociales muy importantes:</p>
<p>¿Quién controla la información que fluye en estas conversaciones, quién regula lo que estos chatbots pueden o no decir o incluso almacenar, y 
    desde dónde o qué intenciones tiene para decir lo que dice? Además, recordemos que el chat GPT se trata de una codificación centralizada en 
    una cultura hegemónica: es decir, la realidad de una cultura será diferente a otra – pero eso, al chat GPT, como que no le importa mucho, la verdad. </p>
<p>Por qué las personas están orilladas a hablar con un chatbot: 
    <ul>
        <li>la búsqueda de una retroalimentación inmediata que un ser humano no siempre puede dar</li>
        <li>miedo que el entorno más inmediato enjuicie o no comprenda la complejidad sobre el tema emocional en cuestión</li>
        <li>ausencia de un colectivo o red de apoyo para fortalecer el sentido de pertenencia</li>
        <li>la inaccesibilidad económica a la salud mental...</li>
    </ul>
<p>Otro problema es la reafirmación del pensamiento, produciendo el sesgo de confirmación. Esto quiere decir que un Chatbot no va a confrontar ni cuestionar tu proceso psicológico y emocional ya que estos chatbots estan diseñados para confirmar tu realidad aunque pueda estar alterada por diversos factores (como neurobiológicos, trastornos mentales o emocionales, contextos sociales, entre otros). </p>
<p>Todo vuelve a un tema sobre quién saca provecho de la precarización de la salud mental de la población con mayores riesgos de exclusión, explotación y pobreza. Y cuando volteamos a ver a los responsables, temiendo a sonar como disco rayado, nos encontramos con los mismos revoltosos: el capitalismo, la colonización, el patriarcado e inclusive el capacitismo. Toca voltear a ver hacia lo colectivo, lo comunitario, para que los cuidados y la ternura radical se conviertan en la nueva revolución de un mundo con justicia social. </p>

<hr>
<h2>Fuentes</h2>
<p>[1]<a href="https://hbr.org/data-visuals/2025/04/top-10-gen-al-use-cases" target="_blank" rel="noopener noreferrer">Top 10 Gen AI use cases 2024 - 2025</a> Harvard bussiness review</p>
<p>[2]<a href="https://futurism.com/chatgpt-mental-illness-medications" target="_blank" rel="noopener noreferrer">ChatGPT Is Telling People With Psychiatric Problems to Go Off Their Meds</a></p>
<p>[3]<a href="https://futurism.com/chatgpt-mental-health-crises" target="_blank" rel="noopener noreferrer">People Are Becoming Obsessed with ChatGPT and Spiraling Into Severe Delusions</a></p>
<p>[4]<a href="https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/" target="_blank" rel="noopener noreferrer">People Are Losing Loved Ones to AI-Fueled Spiritual Fantasie</a></p>
<p>[5]<a href="https://www.youtube.com/watch?v=Qmu6GjNCJTU" target="_blank" rel="noopener noreferrer">ChatGPT is Everyone's Therapist Now? </a></p>
<p>[6]<a href="https://elpais.com/tecnologia/2025-08-25/el-uso-de-chatgpt-como-psicologo-crece-pero-tiene-sus-riesgos-refuerza-el-egocentrismo-y-las-ideas-paranoides.html" target="_blank" rel="noopener noreferrer">El uso de ChatGPT como psicólogo crece, pero tiene sus riesgos: refuerza el egocentrismo y las ideas paranoides</a></p>

<h3>Créditos música</h3>
<p><a href="https://www.youtube.com/watch?v=TuaZ7gDI_tE" target="_blank" rel="noopener noreferrer">MR. BUNGLE - The Holy Filament [piano cover]</a></p>
<p><a href="https://www.youtube.com/watch?v=oRTA5dJbXrM" target="_blank" rel="noopener noreferrer">Aquatic Ambiance (Donkey Kong Country) on piano</a></p>
